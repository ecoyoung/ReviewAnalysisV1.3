import streamlit as st

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Amazonè¯„è®ºåˆ†æ - è¯äº‘åˆ†æ",
    page_icon="â˜ï¸",
    layout="wide"
)

import pandas as pd
import numpy as np
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
import plotly.graph_objects as go
import json
import os
import io

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼ - æ›´æ–°ä¸‹è½½æŒ‰é’®ä¸ºè“è‰²ç³»
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5em;
        margin-bottom: 0.5em;
        font-weight: bold;
    }
    .sub-header {
        text-align: center;
        color: #A23B72;
        font-size: 1.2em;
        margin-bottom: 2em;
    }
    .card {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 8px rgba(0,0,0,0.05);
    }
    .stats-card {
        background-color: #fff;
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 1.2rem;
        margin: 0.5rem;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        transition: all 0.3s ease;
    }
    .stats-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    }
    .section-title {
        color: #2E86AB;
        border-bottom: 2px solid #2E86AB;
        padding-bottom: 0.5rem;
        margin-bottom: 1.5rem;
        font-weight: bold;
    }
    .stButton>button {
        background-color: #2E86AB !important;
        color: white !important;
        border-radius: 8px !important;
        border: none !important;
        padding: 8px 16px !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }
    .stButton>button:hover {
        background-color: #1C6E9C !important;
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1) !important;
    }
    /* æ›´æ–°ä¸‹è½½æŒ‰é’®ä¸ºè“è‰²ç³» */
    .download-button>button {
        background-color: #2E86AB !important;
        color: white !important;
    }
    .download-button>button:hover {
        background-color: #1C6E9C !important;
    }
    .negative-words-list {
        background-color: #e7f3ff;
        border-radius: 8px;
        padding: 1rem;
        margin-top: 1rem;
        border-left: 4px solid #2E86AB;
    }
    .wordcloud-container {
        display: flex;
        justify-content: center;
        padding: 1.5rem;
        background-color: white;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.05);
        margin-bottom: 1.5rem;
    }
    .download-container {
        display: flex;
        gap: 1rem;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

def load_stop_words():
    """åŠ è½½åœç”¨è¯"""
    # åŸºç¡€è‹±æ–‡åœç”¨è¯
    stop_words = {
        # äººç§°ä»£è¯
        'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're",
        "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves',
        'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself',
        'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',
        
        # ç–‘é—®è¯å’ŒæŒ‡ç¤ºè¯
        'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those',
        'where', 'when', 'why', 'how', 'whose',
        
        # å¸¸è§åŠ¨è¯å’ŒåŠ©åŠ¨è¯
        'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',
        'had', 'having', 'do', 'does', 'did', 'doing', 'will', 'would', 'shall',
        'should', 'can', 'could', 'may', 'might', 'must', 'ought', 'need', 'dare',
        
        # ä»‹è¯å’Œè¿è¯
        'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',
        'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',
        'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',
        'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',
        'then', 'once', 'here', 'there', 'all', 'any', 'both', 'each',
        
        # å¸¸è§å‰¯è¯å’Œå½¢å®¹è¯
        'just', 'now', 'only', 'very', 'really', 'quite', 'rather', 'somewhat',
        'more', 'most', 'much', 'many', 'some', 'such', 'no', 'nor', 'not',
        'too', 'very', 'same', 'different', 'other', 'another', 'like', 'unlike',
        
        # æ—¶é—´ç›¸å…³è¯
        'today', 'tomorrow', 'yesterday', 'now', 'later', 'earlier', 'soon',
        'already', 'yet', 'still', 'always', 'never', 'ever', 'often', 'sometimes',
        
        # æ•°é‡è¯å’Œåºæ•°è¯
        'one', 'two', 'three', 'first', 'second', 'third', 'next', 'last',
        'few', 'several', 'many', 'much', 'more', 'most', 'own', 'every',
        
        # å…¶ä»–å¸¸è§è¯
        'yes', 'no', 'maybe', 'ok', 'okay', 'right', 'wrong', 'well', 'anyway',
        'however', 'although', 'though', 'despite', 'unless', 'whereas',
        'whether', 'whatever', 'whoever', 'whenever', 'wherever', 'however',
        
        # ç½‘ç»œç”¨è¯­å’Œç¼©å†™
        'lol', 'omg', 'idk', 'tbh', 'imo', 'imho', 'fyi', 'asap', 'aka'
    }
    
    # æ·»åŠ ä¸€äº›è‡ªå®šä¹‰åœç”¨è¯ï¼ˆä¸äº§å“è¯„è®ºç›¸å…³ï¼‰
    custom_stop_words = {
        # è¯„è®ºå¸¸ç”¨è¯
        'would', 'could', 'get', 'use', 'using', 'used', 'recommend',
        'recommended', 'definitely', 'probably', 'maybe', 'think', 'thought',
        'seems', 'looked', 'looks', 'looking', 'came', 'come', 'goes', 'going',
        'got', 'getting', 'make', 'makes', 'made', 'making',
        
        # æ—¶é—´å’ŒçŠ¶æ€
        'day', 'days', 'week', 'weeks', 'month', 'months', 'year', 'years',
        'time', 'times', 'ago', 'since', 'far', 'long', 'short',
        
        # è¯„åˆ†ç›¸å…³
        'star', 'stars', 'rating', 'rated', 'review', 'reviews', 'reviewed'
    }
    
    return stop_words.union(custom_stop_words)

def load_negative_words():
    """ä»æ–‡ä»¶åŠ è½½å¦å®šè¯åˆ—è¡¨"""
    if os.path.exists('negative_words.json'):
        with open('negative_words.json', 'r') as f:
            return set(json.load(f))
    return set()

def save_negative_words(words):
    """ä¿å­˜å¦å®šè¯åˆ—è¡¨åˆ°æ–‡ä»¶"""
    with open('negative_words.json', 'w') as f:
        json.dump(list(words), f)

def process_text(text, stop_words, negative_words):
    """å¤„ç†æ–‡æœ¬ï¼Œæå–è¯è¯­"""
    if pd.isna(text):
        return []
    
    # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–‡æœ¬å¤„ç†
    text = str(text).lower()
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä¸€æ¬¡æ€§åˆ†è¯
    words = re.findall(r'\b[a-z0-9]+\b', text)
    
    # ä½¿ç”¨é›†åˆæ“ä½œè¿›è¡Œè¿‡æ»¤ï¼Œæé«˜æ•ˆç‡
    filtered_words = [word for word in words 
                     if len(word) > 2 
                     and word not in stop_words 
                     and word not in negative_words]
    
    return filtered_words

def create_wordcloud(text_data, negative_words):
    """åˆ›å»ºè¯äº‘å›¾"""
    # ä¼˜åŒ–è¯äº‘å‚æ•°
    wordcloud = WordCloud(
        width=1600,
        height=800,
        background_color='white',
        max_words=150,
        stopwords=negative_words,
        min_font_size=10,
        max_font_size=150,
        random_state=42  # å›ºå®šéšæœºç§å­ï¼Œæé«˜æ€§èƒ½
    ).generate_from_frequencies(text_data)
    
    # ä½¿ç”¨æ›´é«˜æ•ˆçš„å›¾è¡¨åˆ›å»ºæ–¹å¼
    fig, ax = plt.subplots(figsize=(20, 10), dpi=100)
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    plt.tight_layout(pad=0)
    return fig, wordcloud

def save_wordcloud_to_png(wordcloud):
    """ä¿å­˜è¯äº‘å›¾ä¸ºPNGæ ¼å¼"""
    img_buffer = io.BytesIO()
    wordcloud.to_image().save(img_buffer, format='PNG')
    return img_buffer.getvalue()

def create_word_freq_table(word_freq, top_n=50):
    """åˆ›å»ºè¯é¢‘ç»Ÿè®¡è¡¨"""
    # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®å¤„ç†
    df = pd.DataFrame(list(word_freq.items()), columns=['Word', 'Frequency'])
    df = df.nlargest(top_n, 'Frequency')
    
    # ä¼˜åŒ–è¡¨æ ¼åˆ›å»º
    fig = go.Figure(data=[
        go.Table(
            header=dict(
                values=['è¯è¯­', 'é¢‘ç‡'],
                fill_color='#2E86AB',
                font=dict(color='white', size=14),
                align='center'
            ),
            cells=dict(
                values=[df['Word'], df['Frequency']],
                fill_color='#fafafa',
                align='center',
                font=dict(size=13)
            )
        )
    ])
    
    fig.update_layout(
        margin=dict(l=0, r=0, t=0, b=0),
        height=600
    )
    
    return fig

def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown('<div class="main-header">â˜ï¸ Amazonè¯„è®ºåˆ†æ - è¯äº‘åˆ†æ</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">è¯„è®ºæ–‡æœ¬åˆ†æä¸è¯äº‘å›¾ç”Ÿæˆ</div>', unsafe_allow_html=True)
    
    # åŠ è½½åœç”¨è¯å’Œå¦å®šè¯
    stop_words = load_stop_words()
    negative_words = load_negative_words()
    
    # æ–‡ä»¶ä¸Šä¼ å¡ç‰‡
    st.markdown("### ğŸ“¤ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        uploaded_file = st.file_uploader(
            "é€‰æ‹©é¢„å¤„ç†åçš„Excelæ–‡ä»¶", 
            type=['xlsx'],
            help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šID, Asin, Title, Content, Model, Rating, Date, Review Type"
        )
        st.markdown('</div>', unsafe_allow_html=True)
            
    if uploaded_file is not None:
        try:
            with st.spinner('æ­£åœ¨åŠ è½½æ•°æ®...'):
                df = pd.read_excel(uploaded_file)
            
            # éªŒè¯æ–‡ä»¶æ ¼å¼
            required_columns = ['Content', 'Review Type']
            if not all(col in df.columns for col in required_columns):
                st.error("âŒ è¯·ä¸Šä¼ åŒ…å«Contentå’ŒReview Typeåˆ—çš„é¢„å¤„ç†æ–‡ä»¶ï¼")
                return
            
            st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡è¯„è®º")
            
            # é€‰æ‹©è¯„è®ºç±»å‹
            st.markdown("### ğŸ” é€‰æ‹©åˆ†æèŒƒå›´")
            review_type = st.selectbox(
                "é€‰æ‹©è¦åˆ†æçš„è¯„è®ºç±»å‹",
                ["æ‰€æœ‰è¯„è®º", "Positiveè¯„è®º", "Negativeè¯„è®º", "Neutralè¯„è®º"],
                index=0
            )
            
            # æ ¹æ®é€‰æ‹©ç­›é€‰æ•°æ®
            if review_type == "Positiveè¯„è®º":
                filtered_df = df[df['Review Type'].str.lower() == 'positive']
            elif review_type == "Negativeè¯„è®º":
                filtered_df = df[df['Review Type'].str.lower() == 'negative']
            elif review_type == "Neutralè¯„è®º":
                filtered_df = df[df['Review Type'].str.lower() == 'neutral']
            else:
                filtered_df = df
            
            # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®é‡
            st.info(f"ç­›é€‰å‡º **{len(filtered_df)}** æ¡ **{review_type}**")
            
            # å¦å®šè¯ç®¡ç†å¡ç‰‡
            st.markdown("### ğŸš« å¦å®šè¯ç®¡ç†")
            with st.container():
                st.markdown('<div class="card">', unsafe_allow_html=True)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### â• æ·»åŠ å¦å®šè¯")
                    new_negative_word = st.text_input(
                        "è¾“å…¥è¦æ·»åŠ çš„å¦å®šè¯ï¼ˆå¤šä¸ªè¯ç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰", 
                        placeholder="ä¾‹å¦‚ï¼šamazon, product, supplements",
                        key="add_input"
                    )
                    if st.button("æ·»åŠ å¦å®šè¯", key="add_word") and new_negative_word:
                        # å¤„ç†æ‰¹é‡æ·»åŠ 
                        words_to_add = [word.strip().lower() for word in new_negative_word.split(',') if word.strip()]
                        negative_words.update(words_to_add)
                        save_negative_words(negative_words)
                        st.success(f"âœ… å·²æ·»åŠ  {len(words_to_add)} ä¸ªå¦å®šè¯")
                
                with col2:
                    st.markdown("#### âŒ åˆ é™¤å¦å®šè¯")
                    if negative_words:
                        word_to_remove = st.selectbox("é€‰æ‹©è¦åˆ é™¤çš„å¦å®šè¯", list(negative_words), key="remove_word")
                        if st.button("åˆ é™¤å¦å®šè¯", key="remove_btn"):
                            negative_words.remove(word_to_remove)
                            save_negative_words(negative_words)
                            st.success(f"âœ… å·²åˆ é™¤å¦å®šè¯: **{word_to_remove}**")
                    else:
                        st.info("å½“å‰æ²¡æœ‰è®¾ç½®å¦å®šè¯")
                
                # æ·»åŠ é¢„è®¾å¦å®šè¯å¯¼å…¥
                st.markdown("#### ğŸ“¦ é¢„è®¾å¦å®šè¯")
                preset_words = {
                    "ä¿å¥å“ç›¸å…³": "supplements,supplement,gummy,gummies,capsule,capsules,drop,take,taking,took,also"
                }
                
                col3, col4 = st.columns([3, 1])
                with col3:
                    st.markdown("é¢„è®¾å¦å®šè¯ç±»åˆ«ï¼šè¡¥å……å‰‚ç›¸å…³")
                    st.markdown("åŒ…å«ï¼šsupplements, supplement, capsule, capsules, drop, take, taking, took, also")
                with col4:
                    if st.button("ä¸€é”®å¯¼å…¥é¢„è®¾å¦å®šè¯", key="import_preset"):
                        words_to_add = [word.strip().lower() for word in preset_words["è¡¥å……å‰‚ç›¸å…³"].split(',')]
                        negative_words.update(words_to_add)
                        save_negative_words(negative_words)
                        st.success(f"âœ… å·²å¯¼å…¥ {len(words_to_add)} ä¸ªé¢„è®¾å¦å®šè¯")
                
                # æ˜¾ç¤ºå½“å‰å¦å®šè¯åˆ—è¡¨
                st.markdown("#### ğŸ“ å½“å‰å¦å®šè¯åˆ—è¡¨")
                if negative_words:
                    # ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œé¿å…æ˜¾ç¤ºé—®é¢˜
                    st.markdown(f'<div class="negative-words-list">{", ".join(sorted(negative_words))}</div>', 
                              unsafe_allow_html=True)
                else:
                    st.info("å½“å‰æ²¡æœ‰è®¾ç½®å¦å®šè¯")
                
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ç”Ÿæˆè¯äº‘å›¾æŒ‰é’®
            if st.button("â˜ï¸ ç”Ÿæˆè¯äº‘å›¾", key="analyze", type="primary", use_container_width=True):
                with st.spinner('æ­£åœ¨å¤„ç†è¯„è®ºå†…å®¹...'):
                    all_words = []
                    progress_bar = st.progress(0)
                    total = len(filtered_df)
                    
                    # æ·»åŠ è¿›åº¦æ¡æ›´æ–°é€»è¾‘
                    for i, text in enumerate(filtered_df['Content']):
                        words = process_text(text, stop_words, negative_words)
                        all_words.extend(words)
                        
                        # æ¯å¤„ç†10æ¡æ›´æ–°ä¸€æ¬¡è¿›åº¦æ¡
                        if i % 10 == 0 or i == total - 1:
                            progress_bar.progress((i + 1) / total)
                    
                    # è®¡ç®—è¯é¢‘
                    word_freq = Counter(all_words)
                
                if word_freq:
                    st.success(f"âœ… åˆ†æå®Œæˆï¼å…±æå– {len(word_freq)} ä¸ªæœ‰æ•ˆè¯æ±‡")
                    
                    # æ˜¾ç¤ºç»Ÿè®¡å¡ç‰‡
                    st.markdown("### ğŸ“Š åˆ†æç»Ÿè®¡")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown(f"""
                        <div class="stats-card">
                            <h4 style="color: #2E86AB; margin: 0;">è¯„è®ºæ€»æ•°</h4>
                            <h2 style="color: #A23B72; margin: 0.5rem 0;">{len(df)}</h2>
                            <p style="color: #666; margin: 0;">åŒ…å«æ‰€æœ‰ç±»å‹è¯„è®º</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"""
                        <div class="stats-card">
                            <h4 style="color: #2E86AB; margin: 0;">åˆ†æè¯„è®º</h4>
                            <h2 style="color: #A23B72; margin: 0.5rem 0;">{len(filtered_df)}</h2>
                            <p style="color: #666; margin: 0;">{review_type}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(f"""
                        <div class="stats-card">
                            <h4 style="color: #2E86AB; margin: 0;">æœ‰æ•ˆè¯æ±‡</h4>
                            <h2 style="color: #A23B72; margin: 0.5rem 0;">{len(word_freq)}</h2>
                            <p style="color: #666; margin: 0;">è¿‡æ»¤åå…³é”®è¯</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # è¯äº‘å›¾å±•ç¤º
                    st.markdown("### â˜ï¸ è¯äº‘å›¾")
                    with st.container():
                        st.markdown('<div class="wordcloud-container">', unsafe_allow_html=True)
                        wordcloud_fig, wordcloud = create_wordcloud(word_freq, negative_words)
                        st.pyplot(wordcloud_fig)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # è¯é¢‘ç»Ÿè®¡è¡¨
                    st.markdown("### ğŸ“‹ è¯é¢‘ç»Ÿè®¡è¡¨")
                    with st.expander("ç‚¹å‡»å±•å¼€/æ”¶èµ·è¯é¢‘ç»Ÿè®¡è¡¨", expanded=True):
                        freq_table = create_word_freq_table(word_freq)
                        st.plotly_chart(freq_table, use_container_width=True)
                else:
                    st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è¯è¯­ï¼Œè¯·è°ƒæ•´åˆ†ææ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®ã€‚")
        
        except Exception as e:
            st.error(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    else:
        st.info("â„¹ï¸ è¯·ä¸Šä¼ é¢„å¤„ç†åçš„Excelæ–‡ä»¶å¼€å§‹åˆ†æ")

if __name__ == "__main__":
    main()